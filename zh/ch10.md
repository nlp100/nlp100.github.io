---
title: "第10章：机器翻译"
date: 2020-09-12 18:00:00 +0800
layout: single
toc: true
lang: zh
sidebar: {nav: "sidebar_zh"}
header:
  teaser: /assets/images/ch10.png
---

在本章中，我们将训练一个神经机器翻译(NMT, Neural Machine Translation)模型。对于英语-德语翻译任务，可以使用IWSLT'14英德数据集；对于日语-英语翻译任务，可以使用[京都フリー翻訳タスク (KFTT)](http://www.phontron.com/kftt/index-ja.html)数据集。
在实现NMT模型时，可以使用若干个成熟的工具框架，例如[fairseq](https://github.com/pytorch/fairseq), [Hugging Face Transformers](https://github.com/huggingface/transformers) 与 [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)。



## 90. 数据预处理

下载数据集并对其进行标准化处理、语料清洗等操作，之后将其分为训练集、验证集、测试集。对于英语-德语翻译任务，可以直接使用预处理[脚本](https://github.com/nlp100/nlp100.github.io/blob/master/tools/prepare_mt_data.sh)。对于日语-英语翻译任务，你可能需要进行额外的分词操作，将其划分为不同语言中的最小的语义单位。

## 91. 训练机器翻译模型

使用90问中的数据集进行机器翻译模型的训练（选取适当的模型架构，如基于LSTM的模型，基于Transformer的模型）。

## 92. 使用翻译模型

使用91问中已训练好的翻译模型，并编写程序将给定的任意源语言句子（英语、日语）翻译到到目标语言（德语、英语）。

## 93. BLEU分数

使用91问中训练好的模型，在测试集上计算BLEU分数。

## 94. 束搜索 (Beam search)

当使用91问中训练好的模型翻译给定的句子时，使用束搜索(Beam search)，并尝试更换不同的beam值，从1到100。
接着画出BLEU值随着beam值的变化图。

## 95. Subword

使用基于subword为单位的词表示法，而不是使用基于word为单位的分词。
使用新的词单位表示法，重复91-94问中的实验。


## 96. 学习过程可视化

使用类似[TensorBoard](https://www.tensorflow.org/tensorboard)的工具，并对机器翻译模型训练的过程进行可视化。 
特别地，在训练集、验证集上计算loss与BLEU score这些关键指标，并进行可视化。

## 97. 超参数调整

更改机器翻译模型的架构或者超参数，找到在验证集上达到最高性能的设定。

## 98. 领域自适应
对于英语-德语翻译任务，在newstest2014数据集上评估机器翻译模型，可以使用[sacreBLEU](https://github.com/mjpost/sacreBLEU) 工具进行评估。然后使用[News Commentary](http://data.statmt.org/news-commentary/v15/training/news-commentary-v15.de-en.tsv.gz)数据集评估，并尝试提高模型的翻译表现。

对于日语-英语翻译任务，通过使用如[Japanese-English Subtitle Corpus (JESC)](https://nlp.stanford.edu/projects/jesc/index_ja.html)或者[JParaCrawl](http://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/)数据集，尝试达到KFTT测试数据之上的性能表现。

## 99. 翻译系统服务构建

构建一个demo系统，使用户能够在浏览器中翻译任意文本。